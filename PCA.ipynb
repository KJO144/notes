{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "n = 100\n",
    "p = 10\n",
    "q = 5 # dims to keep\n",
    "X = np.random.randn(n,p)\n",
    "eye = np.ones(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a data matrix $X \\sim n \\times p$. Its (Bessel-corrected) covariance matrix can be written $C = \\frac{1}{n-1} X^T X - \\frac{1}{n^2} \\mu \\mu^T$ where $\\mu$ is the p-vector of column means. We demean $X$ first, so the covariance matrix is just the first term above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First demean. The vector of column means is obtained simply by dotting with an n-vector of ones on the left, and dividing by n.\n",
    "mu = eye@X / n\n",
    "X_dm = X-mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance matrix\n",
    "cov = np.cov(X_dm,rowvar=False)\n",
    "cov2= X_dm.T@X_dm/(n-1)\n",
    "np.testing.assert_almost_equal(cov,cov2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform a standard eigendecomposition. We decompose $C$ as\n",
    "\n",
    "$C = \\frac{1}{n-1} Q D Q^T$\n",
    "\n",
    "where $Q$ is the matrix whose columns are the eigenvectors of $C$, and $D$ is the diagonal matrix of e-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigendecomposition of covariance matrix\n",
    "(evalues, Q) = np.linalg.eig(cov)\n",
    "\n",
    "# sort order of e-values & e-vectors\n",
    "idx = np.argsort(evalues)[::-1]\n",
    "evalues = evalues[idx]\n",
    "Q = Q[:,idx]\n",
    "\n",
    "# confirm that the decomposition works\n",
    "check = Q @ np.diag(evalues) @ Q.T\n",
    "np.testing.assert_almost_equal(check,cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $Q$ in hand we can transform our data. We define\n",
    "\n",
    "$Z = XQ$\n",
    "\n",
    "and observe that the covariance matrix of $Z$ is diagonal:\n",
    "\n",
    "$C_Z = \\frac{1}{n-1} D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new variables Z. They are linear combinations of the old variables.\n",
    "Z = X_dm@Q # both Z and X_dm are nxp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now keep only the first $q$ variables. These are the ones that explain the most variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1507622 , 0.13428279, 0.12666082, 0.10918671, 0.09557138,\n",
       "       0.08983471, 0.08153292, 0.07807001, 0.07574734, 0.05835113])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The fraction of variance explained by each is given by the sum of remaining e-values\n",
    "frac = evalues/np.sum(evalues)\n",
    "frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Z-t (truncated) which keeps only the first q dimensions\n",
    "Z_t = Z[:,0:q]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do PCA is by using the singular value decomposition on the data matrix (not on the covariance matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "(U, s, VT) = np.linalg.svd(X_dm)\n",
    "\n",
    "d = np.diag(s)\n",
    "sigma = np.pad(d,((0,n-p), (0,0)), 'constant')\n",
    "np.testing.assert_almost_equal(X_dm, U@sigma@VT)\n",
    "\n",
    "# define new variables Z\n",
    "Z = X_dm@VT.T\n",
    "\n",
    "#sigma.T@sigma/(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1507622 , 0.13428279, 0.12666082, 0.10918671, 0.09557138])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now do it using sklearn\n",
    "pca = PCA(q)\n",
    "pca.fit(X)\n",
    "Z = pca.transform(X)\n",
    "pca.explained_variance_ratio_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
